{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhimanyubellam/Library/Python/3.7/lib/python/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../Datasets\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"../Datasets\", train=True, download=False, transform=transform)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../Datasets\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = datasets.MNIST(\n",
    "    root=\"../Datasets\", train=False, download=False, transform=transform)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "test_loadder = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_net import BasicNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_net1 = BasicNet()\n",
    "cost_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init bacth shape torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print (\"init bacth shape\", images.size())\n",
    "    break\n",
    "images.view(1,-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generations, model):\n",
    "    best_candidate_losses = []\n",
    "    for i in tqdm(range(generations)):\n",
    "        gen_train_loss=[]\n",
    "        gen_train_acc=0\n",
    "        for b, (X_train, y_train) in enumerate(train_loader):\n",
    "            b+=1\n",
    "            # run model, get loss\n",
    "            y_pred = model(X_train.view(batch_size, -1)) # flatten and evaluate\n",
    "            loss = cost_func(y_pred, y_train)\n",
    "            gen_train_loss.append(loss)\n",
    "            \n",
    "            \n",
    "            predicted = torch.max(y_pred.data, 1)[1]\n",
    "            \n",
    "            gen_train_acc+= (predicted==y_test).sum()\n",
    "            \n",
    "            \n",
    "            \n",
    "            # visualize for best candidate\n",
    "        gen_train_loss_total = sum(gen_train_loss)\n",
    "        print (f\"Gen:{i}, loss: {gen_train_loss_total}, acc: {gen_train_acc}\")\n",
    "        \n",
    "        #evolve\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1593,  0.0225,  0.2888,  0.3428],\n",
       "        [-0.3278, -0.0073,  0.2181,  0.4480],\n",
       "        [-0.0464, -0.2075, -0.2040, -0.3577],\n",
       "        [-0.0382,  0.1869,  0.0812,  0.3034],\n",
       "        [-0.0933,  0.2894, -0.1449, -0.4228],\n",
       "        [ 0.2317, -0.3001, -0.2485,  0.1962],\n",
       "        [ 0.2957,  0.0304, -0.0007,  0.4728],\n",
       "        [-0.4343,  0.2107,  0.3733, -0.3766],\n",
       "        [-0.3006,  0.4164,  0.0547,  0.2784],\n",
       "        [-0.4473,  0.0134,  0.0057, -0.1768]], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_net1.d3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2848,  0.2090,  0.4117, -0.3648],\n",
       "        [-0.0597, -0.1142,  0.4644, -0.1160],\n",
       "        [-0.2047, -0.4819,  0.3412,  0.2054],\n",
       "        [ 0.0358, -0.0541, -0.4511, -0.3880],\n",
       "        [-0.4673, -0.1311, -0.0020,  0.1218],\n",
       "        [ 0.1130, -0.4485, -0.2412,  0.2773],\n",
       "        [-0.4218, -0.2839,  0.3953,  0.1766],\n",
       "        [-0.3097,  0.3797,  0.3349,  0.1339],\n",
       "        [-0.3377,  0.1392, -0.3575, -0.2464],\n",
       "        [-0.1845,  0.3202,  0.1019,  0.1065]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_net2 = BasicNet()\n",
    "basic_net2.d3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_net2.d3.weight.flatten().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_net2.d3.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.zeros((4,10))\n",
    "arr = torch.tensor(arr)\n",
    "with torch.no_grad():\n",
    "    basic_net2.d2.weight.data=arr\n",
    "basic_net2.d2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_net2.d3.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
